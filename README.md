#BeerGen
I built a script for a hackathon we did last year which creates a product catalog.  It was designed to be a dataset we could use for testing the Faceted Search capability introduced in 3.4 but It seems to be a good dataset to demo Compass with.  Talking about beer, especially craft beer, especially fake craft beer with silly names seems to warm up any customer meeting.

The script is written in Go and requires a bunch of libraries to be used, so It's probably not worth the hassle to try and run it yourself. However, it is in the github repo so feel free to go play.

What is probably more interesting is this...

https://github.com/jimb-cc/BeerGen/tree/master/sample_data
...Which is a couple of Mongo Dumps which you can restore into your own DB and use for demos.

There are two datasets here. 

The first one is called Beer_10k which you might expect to have 10,000 records of fake beer in it.  It doesn't, it actually has 20,000.  I don't know why, I must have run the script twice or something.
The second is Beer_1m which you might expect to have 1 million fake beers in it. Surprisingly, due to a freak of temporal topography, it actually does.
 The talk track I use around this is something like:

(as I boot up compass) "I know it's only 10am, but I thought I'd show you my beer collection" (obviously, choose the correct Time.now). "I built a script for a hackathon a couple of weeks ago, which generates fake beers on demand.  lots of them."
(go to the document view in compass) "This is what they look like.  They each have a name, price, rating out of 10, blah blah blah"  (take them through the document structure so they can see the documents.  Make sure you zoom compass in (ctrl/cmd+) so that it's big enough to read for the folks at the back of the room.)
(go to the schema view) "Compass has a great way of visualising the schmea of your collection and the distribution of the data within.  You can see that most beers score a rating of 6 to 9 ish out of 10" (scroll up and down the page a bit)
(still in the schema view) "But the schema view allows you to drill into your data too, I might want to say that I'm particularly interested in beers that have the type 'Summer Ale' (click on summer ale in the type - or anything else that catches your eye) "and perhaps I really, really like beers brewed with 'Old Golden' hopps" (click on that too). "but I'm also a bit of a beer snob, so I'm only interested in beers which scored 8,9 or 10 out of 10 on the rating" (click and drag over the 8,9 and 10 bars in the rating field, to select those values).  "However, because I grew up in the (north|south|midlands|wales|scotland[*select only one from that list]) I'm really tight and don't like paying for my beer, so I'm interested in only the very cheapest beers (click and drag over the lowest three bars in the price field).
"As I click around, you can see that compass is building a query up here" (points to the query bar) "we can now run this query" (press the big green button) "and look, we've reduced down from 1,000,000 documents to 28." 
 "Lets go back to the document view" (go back to the document view) "these are the 28 beers that matched my query."  (scroll down the list a bit, choose one at random) Ohhh.. look at this one, hahaha isn't that a silly name. this is my new favorite. (now click on the little pencil icon in the top right corner of the document view - we're going to edit the document.  once in edit mode, put your mouse over the field number of the last field in the document (usually the 10) and it turns into a '+', click that plus, then the 'add field after xxxx' button ) "I'm going make sure I don't forget this one" (add a key for "Jim Approves" - except best to use your own name, and then a value of 'True' or something similar).  "And because i really like it I'm going to give it a rating of 11/10" (double click on the rating value and change it to 11), but I don't want anyone to know how much it cost, so we'll just get rid of that (press on the little 'X' next to the price field to delete it.  Finally, click the 'update' button in the lower right or that document).  "And, we've just updated that document.  It's that easy.  Without having to change any schemas, or alter any tables, we've been able to remove fields, add fields, and modify values. That's the power of MongoDB's flexible data model'
(next up, we'll look at the visual explain plan) "you'll notice that we built up a pretty big query back there.  It's good to know how that is being executed.  If you come from an RDBMS background, you'll be familiar with explain plans, mongoDB has the same.  Compass goes one better and allows you to visualise the explain plan so you can see very quickly if we are hitting the right indexes for this query. (depending on how you've indexed this dataset, you may hit an index or not, amend your talk track to reflect what you see).
"We can also use compass to build indexes if we need to" (go to the index tab) "here we can see the indexes we've got in place, and build a new one if we need to." (click add new index) "We might want to be doing queries on breweries in different cities, so a compound index of both Brewery and Filed might help us" (you can build the index, but if it's on the 1m beer dataset it might take a bit of time).  
(Go to the Document Validation tab) "you can also use Compass to build document validation rules, we spoke about this earlier, right?" (you did talk about this earlier right? when you were discussing how awesome mongo is? and how just because we've got a flexible schema doesn't mean we don't do governance, right?) "we can impose roles on the documents, such as "name must be a string", "brewery must exist" and "rating must be a number between 0 and 10".  Note that if we'd had this enabled when we modified the document earlier, I would have warned me when I'd modified the rating to be 11" (I'm not actually sure if this is true, I've never actually tried it.  Reader, Beware.)
Obviously, it's much better to find your own flow, but feel free to use mine if you want. Note, that right now, this dataset doesn't make use of any geospatial data, but I plan to fix that.  In the meantime, keep reading, I have datasets aplenty with quality* geo data included (*for varying defintions of the word 'quality') 

